# Detect the Bias
> 
> Biased data may lead to biased predictions, and AI models are only as fair as their training data. It’s important to be aware of the possibility of bias, so that you can mitigate against it.
> 
> In this hands on lab, you will see how different datasets affect the predictions of an AI model. Rate the fairness of the outcomes, and see if other people agree. Then learn why reducing bias in AI models is so important.
> 
> **_Note:_** Detect the Bias is a live online demo, so you may see different models and datasets than those pictured below.
> 
> ## Follow these steps to explore the demo:
> 
> 1\. Access the demo here: [Detect the Bias](http://biasreduction.mybluemix.net/ "Detect the Bias demo")
> 
> 2\. On the **Detect the Bias** page, read the introductory text, and then click **Get Started**.
> 
> 3\. In the Consent message box, click **I agree**, and then click **Next**.
> 
> 4\. Page 1 of 3 describes the data the model uses, and how it might affect the defendant. Read the text, and then click **Next**.
> 
> 5\. Page 2 of 3 tells you that the data has now been preprocessed to make the decision more fair. Read the text, and then click **Next**.
> 
> 6\. Page 3 of 3 presents a rules-based model, and the outcome for a particular group. Read the page and then click **FAIR** or **UNFAIR** based on your evaluation of the model.
> 
> ![](https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/UROYvaypEemrTApEFxJINg_6e44a32afddc486b113683c8863f2076_Detect-the-Bias-1b.PNG?expiry=1592784000000&hmac=QrZU9_X2TCNxlQVwW95hfVnoGJZz3Q1_SGfSO1_khxM)
> 
> 7\. Click **Submit Answer**.
> 
> The **Round 1** page shows the decision tree the model used to make the decision.
> 
> 8\. Read the page and then click **FAIR** or **UNFAIR** based on your evaluation of the model.
> 
> ![](https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/M-hVQ6yrEem5YwqUxVF09g_1125910b15988116300de2581d9d6273_Detect-the-Bias-2b.PNG?expiry=1592784000000&hmac=AxE29qBQlNqlNU2jQMWj_u_kan1btlzHB8L0FdJoVgA)
> 
> 9\. Click **Submit Answer**.
> 
> 10\. The message box confirms your choice, and tells you how many people agreed with you. Click **Next**.
> 
> The **Round 2** page shows the weighted model with the relative weights applied to key attributes that the model used to make this decision.
> 
> 11\. Read the page and then click **FAIR** or **UNFAIR** based on your evaluation of the model.
> 
> ![](https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/G44bCKywEemO6w5N_OSWEg_72e9640f215f8ab0d60c78ea0ff1accd_Detect-the-Bias-3c.PNG?expiry=1592784000000&hmac=15Rk0CTZht56tPr3lb2nJiMwMpWqWc8sBQgaRoCPFns)
> 
> 12\. Click **Submit Answer**.
> 
> 13\. The message box confirms your choice, and tells you how many people agreed with you. Click **Next**.
> 
> The **Round 3** page shows the decision tree the model used to make this decision.
> 
> 14\. Read the page and then click **FAIR** or **UNFAIR** based on your evaluation of the model.
> 
> ![](https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/5SzjuKyrEemJ1w4LYV5qDg_67d4f60ddf0775246dee4459d260d4f5_Detect-the-Bias-4b.PNG?expiry=1592784000000&hmac=h_o0O-sm2Zm06Yb51aFIpTek1PjINT_ru4b7PbxGfIo)
> 
> 15\. Click **Submit Answer**.
> 
> 16\. The message box confirms your choice, and tells you how many people agreed with you.Click **Next**.
> 
> The **Round 4** page shows the decision tree the model used to make this decision.
> 
> 17\. Read the page and then click **FAIR** or **UNFAIR** based on your evaluation of the model.
> 
> ![](https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/CNo6rKytEemL4BKJFeiPYA_b6c76cd2bac2f34c657a7a8d1c6b3a9f_Detect-the-Bias-5b.PNG?expiry=1592784000000&hmac=jNp7xNLcegLFqRG6CgxZ7_vjaC-QMNgjRL6iGbtKxP8)
> 
> 18\. Click **Submit Answer**.
> 
> 19\. The message box confirms your choice, and tells you how many people agreed with you. Click **Next**.
> 
> The final page summarizes the results.
> 
> 20\. If you wish to provide your age and gender, do so. It is not required.
> 
> 21\. Click **Submit Answer**.
> 
> [Optional]: On the Learn More page, click the link to get more information about IBM’s research on Fairness in Models.
> 
> 22\. Click **Exit**.
> 
> Use the Discussion Forum to talk about the models with your fellow students.
> 
> *   Which model did you feel was most fair?
> *   What attribute seems to have most effect on re-offending?
>
> -- https://www.coursera.org/learn/introduction-to-ai/supplement/cAfOE/optional-hands-on-lab-detect-the-bias#main
