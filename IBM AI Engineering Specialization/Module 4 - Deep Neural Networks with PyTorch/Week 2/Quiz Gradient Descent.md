## Gradient Descent
> 
> Latest Submission Grade
> 
> 100%
> 
> 1.
> 
> Question 1
> 
> In gradient descent, what happens when you select a learning rate that is too large?
> 
> 1 / 1 point
> 

      You may miss the minimum and your loss will start increasing 
> 
>  It may take to long to converge to a minimum 
> 
>  The loss function will become concave 
> 
> Check
> 
> Correct
> 
> correct
> 
> 2.
> 
> Question 2
> 
> How do you select an initial parameter value for the first iteration of gradient descent?
> 
> 1 / 1 point
> 
>  Set it to 100 
> 
>  It should always be 0 
> 

      Randomly 
> 
> Check
> 
> Correct
>
> -- https://www.coursera.org/learn/deep-neural-networks-with-pytorch/exam/4moGG/gradient-descent/attempt?redirectToCover=true#Tunnel Vision Close
