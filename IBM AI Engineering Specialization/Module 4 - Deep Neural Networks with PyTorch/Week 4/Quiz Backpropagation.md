## Backpropagation
> 
> Latest Submission Grade
> 
> 100%
> 
> 1.
> 
> Question 1
> 
> True or False? If the derivative of all the sigmoid functions are approximately zero, therefore, when we apply the update equation for gradient decent, nothing will happen.
> 
> 1 / 1 point
> 

      True 
> 
>  False 
> 
> Check
> 
> Correct
> 
> correct
> 
> 2.
> 
> Question 2
> 
> What is the approximate value of the product of a large number of terms that are approximately zero ? hit use the following image from the video:
> 
> ![](https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/Xj9v9OuZEemuKg4HYO6kCg_eb7bfb7ab97bcd51c76214eacc2c40be_Screen-Shot-2019-10-10-at-4.01.24-PM.png?expiry=1598918400000&hmac=vRPhH3QpqIU3LOEXaScNbjgnsVJzPzXBHm1CQv_zxzw)
> 
> 1 / 1 point
> 

      0 
> 
>  1 
> 
> Check
> 
> Correct
> 
> correct
>
> -- https://www.coursera.org/learn/deep-neural-networks-with-pytorch/exam/rIcK5/backpropagation/attempt?redirectToCover=true#Tunnel Vision Close
