## Feature extraction from text and images
> 
> Total points 4
> 
>  1.Question 1
> 
> TF-IDF is applied to a matrix where each column represents a word, each row represents a document, and each value shows the number of times a particular word occurred in a particular document. Choose the correct statements.
> 
> 1 / 1 point 
> 
>  TF normalizes sum of the column values to 1 
> 

      IDF scales features inversely proportionally to a number of word occurrences over documents 
> 
> Check
> 
> Correct
> 
> Correct! Purpose of IDF is to decrease importance of most frequent words.
> 

      TF normalizes sum of the row values to 1 
> 
> Check
> 
> Correct
> 
> Correct!
> 
>  IDF scales features proportional to the frequency of wordâ€™s occurrences 
> 
>  2.Question 2
> 
> What of these methods can be used to preprocess texts?
> 
> 1 / 1 point 
> 

      Lowercase transformation 
> 
> Check
> 
> Correct
> 
> Correct! Lowercase is used to unite words written in UPPERCASE and lowercase.
> 

      Lemmatization 
> 
> Check
> 
> Correct
> 
> Correct! Lemmatization is used to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form.
> 

      Stemming 
> 
> Check
> 
> Correct
> 
> Correct! Stemming is used to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form.
> 
>  Levenshteining 
> 
>  Plumping 
> 
>  Plumbing 
> 

      Stopwords removal 
> 
> Check
> 
> Correct
> 
> Correct! After feature generation stopwords result in useless features that interfere with useful ones.
> 
>  3.Question 3
> 
> What is the main purpose of Lemmatization and Stemming?
> 
> 1 / 1 point 
> 
>  To induce common word amplification standards to the most useful for machine learning algorithms form. 
> 
>  To reduce significance of common words. 
> 

      To reduce inflectional forms and sometimes derivationally related forms of a word to a common base form. 
> 
>  To remove words which are not useful. 
> 
> Check
> 
> Correct
> 
> You are right, this is the exact purpose of Lemmatization and Stemming!
> 
>  4.Question 4
> 
> To learn Word2vec embeddings we need ...
> 
> 1 / 1 point 
> 

      Text corpora 
> 
> Check
> 
> Correct
> 
> Correct. To learn more about word embeddings, I encourage you to check out the course on Deep Learning in our specialization.
> 
>  Labels for each word in the documents in the corpora 
> 
>  GloVe embeddings 
> 
>  Labels for the documents in the corpora
>
> -- https://www.coursera.org/learn/competitive-data-science/quiz/dmWhE/feature-extraction-from-text-and-images/attempt?redirectToCover=true#Tunnel Vision Close
