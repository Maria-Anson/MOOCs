{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Generating names with recurrent neural networks RNN-task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvd0NvIxgVeL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fef6f12c-efa8-47c5-fb8c-bb181b23f225"
      },
      "source": [
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfT6ZHVWglgJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "00380082-fb75-4696-d3e4-46481fef3e0b"
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week2_honor()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-11 11:10:48--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-07-11 11:10:49 (44.6 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlikPrgpgVeU",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "LKwzQ2l4gVeW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "fa77751d-cf4c-4d46-e5ab-6436e75a3b58"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9-hPJsqgVec",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "is37WqG5gVed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ_riCa7om58",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "1e226bca-6404-405e-d39d-8736c2f0d93a"
      },
      "source": [
        "names[0:10]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Abagael',\n",
              " ' Abagail',\n",
              " ' Abbe',\n",
              " ' Abbey',\n",
              " ' Abbi',\n",
              " ' Abbie',\n",
              " ' Abby',\n",
              " ' Abigael',\n",
              " ' Abigail',\n",
              " ' Abigale']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Qc7WE_ypRcH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "4bb387ee-a1f9-4bdb-abbc-1e84fb3aa7f5"
      },
      "source": [
        "names[::1000]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Abagael',\n",
              " ' Claresta',\n",
              " ' Glory',\n",
              " ' Liliane',\n",
              " ' Prissie',\n",
              " ' Geeta',\n",
              " ' Giovanne',\n",
              " ' Piggy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "mZSemTtlgVej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "c43e00a7-2dba-448f-84cf-089cc451f561"
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usXeTIzfplJd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "75abf48b-8e99-4b99-cc24-9eb286bb2ffe"
      },
      "source": [
        "for i in map(len,names[0:10]):\n",
        "  print(i)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "8\n",
            "5\n",
            "6\n",
            "5\n",
            "6\n",
            "5\n",
            "8\n",
            "8\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "jzMicaOGgVev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "9ff93146-f756-443d-d5c2-e5783de75e64"
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C5hej2YgVe5",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "XLk26sE6gVe7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33f91828-3c31-4c4a-bf5f-1e1413257b92"
      },
      "source": [
        "tokens = set(''.join(names))\n",
        "tokens.add('#')         ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkFfljbTtF-S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9b6a6691-1f98-40c4-ca10-06a0c6d25b90"
      },
      "source": [
        "print(tokens)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['-', \"'\", 'm', 'g', 'q', 'F', 'G', 'X', 'O', 'A', 'v', 'H', 'Y', 'l', 'x', 'c', 'p', 'i', 'k', 'I', 'h', 'D', 'r', 'C', 'R', 'Z', 'y', 'P', 'Q', 'W', ' ', 'w', 'T', 'd', 'M', 'f', 'o', 't', '#', 's', 'e', 'u', 'J', 'N', 'j', 'L', 'b', 'K', 'V', 'S', 'a', 'E', 'n', 'U', 'z', 'B']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuAESv_NgVfC",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "elWknXb_gVfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_to_id = {token:tokens.index(token) for token in tokens}  ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "bj0t7BHlgVfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "    print(len(names_ix))\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i])) #values for token without padding\n",
        "        names_ix[i, :len(name_ix)] = name_ix #appending token with pad\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "UQiHlFk8gVfU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "07e6863b-9a0d-48a4-d642-6aa692efe29a"
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "4\n",
            "[[30  9 46 50  3 50 40 13 38]\n",
            " [30  6 13 36 22 26 38 38 38]\n",
            " [30 27 22 17 39 39 17 40 38]\n",
            " [30  6 17 36 10 50 52 52 40]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVChM0e4gVfb",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "hSBSHnUhgVfc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "21e0da66-b45b-449f-d33f-0ee6fa8ac10b"
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJwTInpX2GAd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b919ad9-05d3-4718-933e-9219774ec46c"
      },
      "source": [
        "n_tokens"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "xhY3Up8KgVfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation='tanh')               ### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation='softmax')### YOUR CODE HERE "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZF6o4sggVf2",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "_wJKfPFCgVf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = concatenate([x_t_emb,h_t])  ### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(inputs=x_and_h)    ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(inputs=h_next)   ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQnLTx-tgVf8",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "CcSIAp0sgVf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emPlUf-KgVgC",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "LZ0RqxsYgVgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX5QVucPgVgI",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "FVKlbw1zgVgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "\n",
        "loss = tf.reduce_mean(answers_matrix* tf.log(predictions_matrix))       ### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer(0.00001).minimize(loss)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J0ptoL6gVgO",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "u3GZSBwTgVgP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "bab7be1f-46f5-4736-cc57-4943f148fa92"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vktpSSnBgVgW",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "MtF7p_pXgVgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "lsnWvrNngVgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "YrIfq0WLgVgh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "6fac8f0e-95c8-4f48-e754-d4eb27a9a104"
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " AfB VHFhMkfILbz\n",
            " fTsLoBUihRaeLJU\n",
            " TBWgVCMsSDKNiVg\n",
            " wfwYkKLNMdCxxVx\n",
            " uouigFoyIEzkDxd\n",
            " gJyspMJLSIQlRdi\n",
            " bqFhsThS-WcmDxh\n",
            " NoFCybZorh'yyZW\n",
            " wXAxiChvtRSsdgx\n",
            " fx QxdEdugxNFK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "HDL6ZbE-gVgm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "051dbd74-e118-4862-c3ca-5b4208515e56"
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " TrumpRUYCJVSMZx\n",
            " TrumpMedNUWXyMr\n",
            " TrumpmhKdlNiKlD\n",
            " TrumpdxS'QLxLxN\n",
            " TrumpYgX''NLxlQ\n",
            " Trump-nrhSyNSSD\n",
            " TrumpSRLVSWSL'N\n",
            " TrumpShVjcyMCdY\n",
            " TrumpZJtUNkxtMl\n",
            " TrumpIa -WrUxyh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6Y1jww1gVgq",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "agyBVUirgVgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"YKybGReoVqc7Hngx\"\n",
        "COURSERA_EMAIL = \"mariaansona@gmail.com\""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "YhpbsKp1gVgu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "257d7d7f-9a5f-49ed-b2c4-deeef92a3958"
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyzO6dvWgVgz",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "dAX5C9mtgVg1",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "O5XdlSJagVg1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "6bc34998-8903-4aa7-e9d0-4608ba925365"
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.float32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Entity <bound method CustomRNN.call of <__main__.CustomRNN object at 0x7f36dd7cdf60>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method CustomRNN.call of <__main__.CustomRNN object at 0x7f36dd7cdf60>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "LSTM outputs for each step [batch,time,n_tokens]:\n",
            "10\n",
            "(10, 50, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfjoWPgDgVg5",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "r4qjbngfgVg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "219795eb-64b9-4924-e46f-8bbae4147a78"
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "zBTT2tfNgVg8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "c87d6f22-9ae2-4da6-c84b-687fb6d09ea4"
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-52-62766a2145fb>:6: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMxqR7g1oq5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
