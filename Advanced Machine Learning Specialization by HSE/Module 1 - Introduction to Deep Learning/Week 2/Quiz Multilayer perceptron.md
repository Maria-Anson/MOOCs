# Multilayer perceptron
> 
> Total points 4
> 
>  1.Question 1
> 
> Choose the correct statements about MLP
> 
> 1 point 
> 

      We can train MLP with SGD 
> 
>  MLP can have only 1 hidden layer 
> 

      A hidden layer of MLP automatically learns new helpful features for the task 
> 
>  The first hidden layer contains predictions for your task 
> 
>  MLP with a linear activation function is better than a linear model 
> 
>  2.Question 2
> 
> Apply a chain rule to calculate ∂a∂x \frac{\partial a}{\partial x} ∂x∂a​ where a(x,y)=sin(xy)⋅ex a(x, y) = sin(xy)\cdot e^x a(x,y)=sin(xy)⋅ex.
> 
> **Here is an example of the syntax: sin(x*y)*exp(x), more info [here](https://learner.coursera.help/hc/en-us/articles/208279916-Math-assignments "here")**
> 
> 1 point 
> 
> Preview
> 

     (ycos⁡(xy)+sin⁡(xy))e^x
> 
>  3.Question 3
> 
> Choose the correct statements about backpropagation
> 
> 1 point 
> 

      It is the way to train modern neural networks 
> 

      It is an efficient way to apply a chain rule 
> 
>  It is done in one pass 
> 
>  You can use non-differentiable loss to train your MLP 
> 
>  4.Question 4
> 
> What is the time complexity of backpropagation algorithm w.r.t. number of edges NNN in the computational graph?
> 
> 1 point 
> 
>  O(N!) O(N!) O(N!) 
> 
>  O(N2) O(N^2) O(N2) 
> 

      O(N) O(N) O(N) 
> 
>  O(log(N)) O(log(N)) O(log(N))
>
> -- https://www.coursera.org/learn/intro-to-deep-learning/exam/Yveh9/multilayer-perceptron/attempt#Tunnel Vision Close
