{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea88b79-841e-485d-82d6-ef0be134c1c9",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5c4ba85d-7fdc-4352-8f65-e810b4ff6fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b52104d7-9547-417e-8aae-c3635066e919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "\n",
       "                                              review  rating  sentiment  \n",
       "0  All of my kids have cried non-stop when I trie...       5          1  \n",
       "1  We wanted to get something to keep track of ou...       5          1  \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1  \n",
       "3  One of baby's first and favorite books, and it...       4          1  \n",
       "4  Very cute interactive book! My son loves this ...       5          1  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the csv file and displaying the first 5 rows of the dataframe.\n",
    "products = pd.read_csv(r'Dataset/amazon_baby_subset.csv')\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7cfb5e5d-1dad-4c97-8a23-f8c1f7ad9d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baby', 'one', 'great', 'love', 'use', 'would', 'like', 'easy', 'little', 'seat', 'old', 'well', 'get', 'also', 'really', 'son', 'time', 'bought', 'product', 'good', 'daughter', 'much', 'loves', 'stroller', 'put', 'months', 'car', 'still', 'back', 'used', 'recommend', 'first', 'even', 'perfect', 'nice', 'bag', 'two', 'using', 'got', 'fit', 'around', 'diaper', 'enough', 'month', 'price', 'go', 'could', 'soft', 'since', 'buy', 'room', 'works', 'made', 'child', 'keep', 'size', 'small', 'need', 'year', 'big', 'make', 'take', 'easily', 'think', 'crib', 'clean', 'way', 'quality', 'thing', 'better', 'without', 'set', 'new', 'every', 'cute', 'best', 'bottles', 'work', 'purchased', 'right', 'lot', 'side', 'happy', 'comfortable', 'toy', 'able', 'kids', 'bit', 'night', 'long', 'fits', 'see', 'us', 'another', 'play', 'day', 'money', 'monitor', 'tried', 'thought', 'never', 'item', 'hard', 'plastic', 'however', 'disappointed', 'reviews', 'something', 'going', 'pump', 'bottle', 'cup', 'waste', 'return', 'amazon', 'different', 'top', 'want', 'problem', 'know', 'water', 'try', 'received', 'sure', 'times', 'chair', 'find', 'hold', 'gate', 'open', 'bottom', 'away', 'actually', 'cheap', 'worked', 'getting', 'ordered', 'came', 'milk', 'bad', 'part', 'worth', 'found', 'cover', 'many', 'design', 'looking', 'weeks', 'say', 'wanted', 'look', 'place', 'purchase', 'looks', 'second', 'piece', 'box', 'pretty', 'trying', 'difficult', 'together', 'though', 'give', 'started', 'anything', 'last', 'company', 'come', 'returned', 'maybe', 'took', 'broke', 'makes', 'stay', 'instead', 'idea', 'head', 'said', 'less', 'went', 'working', 'high', 'unit', 'seems', 'picture', 'completely', 'wish', 'buying', 'babies', 'won', 'tub', 'almost', 'either']\n"
     ]
    }
   ],
   "source": [
    "# Reading the important words from the json file.\n",
    "import json\n",
    "with open('Dataset/important_words.json','rb') as file:\n",
    "    important_words = json.load(file)\n",
    "# It prints the list of important words.\n",
    "print(important_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ede9412-6ad5-43e9-91fa-2d44dcc8a506",
   "metadata": {},
   "source": [
    "## Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9c003e4b-6fc7-4218-926d-fce891a7cd3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>My daughter had her 1st baby over a year ago S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>One of babys first and favorite books and it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Very cute interactive book My son loves this b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  All of my kids have cried non-stop when I trie...       5          1   \n",
       "1  We wanted to get something to keep track of ou...       5          1   \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1   \n",
       "3  One of baby's first and favorite books, and it...       4          1   \n",
       "4  Very cute interactive book! My son loves this ...       5          1   \n",
       "\n",
       "                                        review_clean  \n",
       "0  All of my kids have cried nonstop when I tried...  \n",
       "1  We wanted to get something to keep track of ou...  \n",
       "2  My daughter had her 1st baby over a year ago S...  \n",
       "3  One of babys first and favorite books and it i...  \n",
       "4  Very cute interactive book My son loves this b...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    \"\"\"\n",
    "    The function takes in a string, and returns a new string with all of the punctuation removed. \n",
    "    \n",
    "    The function uses Python's built-in string.punctuation variable, which is a string of all the punctuation characters. \n",
    "    \n",
    "    The function str.translate() takes in a translation table, which you can generate using the maketrans() helper function\n",
    "    in the string library. \n",
    "    \n",
    "    :param text: The text to be processed\n",
    "    :return: A string with all punctuation removed.\n",
    "    \"\"\"\n",
    "    import string\n",
    "    return str(text).translate(str.maketrans('', '', string.punctuation)) \n",
    "\n",
    "# Applying the remove_punctuation function to the review column of the products dataframe.\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)\n",
    "\n",
    "# Displaying the first 5 rows of the dataframe.\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f736ca3d-37b6-40e0-ac4d-2ed329787e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name             90\n",
       "review          241\n",
       "rating            0\n",
       "sentiment         0\n",
       "review_clean      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting the number of missing values in each column.\n",
    "products.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e8d23972-6f43-48dc-8d3f-439cb3738b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all the empty name, reviews with an empty string.\n",
    "products = products.fillna({'name':'', 'review':''})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb7b13f-b05e-4ae1-99df-ad895e59c55d",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "85d64fad-5c9c-4a76-94a2-4dcee1aca962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column for each word in important_words and populating it with the number of times that word appears in the review.\n",
    "for word in important_words:\n",
    "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bd7ad336-8b85-40fc-8424-4c7dd2f1ba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_15632\\104910223.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  products['contains_perfect'] = products['perfect'] >=1\n"
     ]
    }
   ],
   "source": [
    "# Creating a new column in the product dataframe called 'contains_perfect' and it is counting the number of times the word 'perfect' appears in the review_clean column.\n",
    "products['contains_perfect'] = products['perfect'] >=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "80e97229-4a06-4a2a-9bd4-910794045e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>baby</th>\n",
       "      <th>one</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>use</th>\n",
       "      <th>...</th>\n",
       "      <th>picture</th>\n",
       "      <th>completely</th>\n",
       "      <th>wish</th>\n",
       "      <th>buying</th>\n",
       "      <th>babies</th>\n",
       "      <th>won</th>\n",
       "      <th>tub</th>\n",
       "      <th>almost</th>\n",
       "      <th>either</th>\n",
       "      <th>contains_perfect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>My daughter had her 1st baby over a year ago S...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>One of babys first and favorite books and it i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Very cute interactive book My son loves this b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  All of my kids have cried non-stop when I trie...       5          1   \n",
       "1  We wanted to get something to keep track of ou...       5          1   \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1   \n",
       "3  One of baby's first and favorite books, and it...       4          1   \n",
       "4  Very cute interactive book! My son loves this ...       5          1   \n",
       "\n",
       "                                        review_clean  baby  one  great  love  \\\n",
       "0  All of my kids have cried nonstop when I tried...     0    0      1     0   \n",
       "1  We wanted to get something to keep track of ou...     0    0      0     0   \n",
       "2  My daughter had her 1st baby over a year ago S...     1    0      0     0   \n",
       "3  One of babys first and favorite books and it i...     0    0      0     0   \n",
       "4  Very cute interactive book My son loves this b...     0    0      1     0   \n",
       "\n",
       "   use  ...  picture  completely  wish  buying  babies  won  tub  almost  \\\n",
       "0    0  ...        0           0     0       0       0    0    0       0   \n",
       "1    0  ...        0           0     0       0       0    0    0       0   \n",
       "2    0  ...        0           0     0       0       0    0    0       0   \n",
       "3    0  ...        0           0     0       0       0    0    0       0   \n",
       "4    0  ...        0           0     0       0       1    0    0       0   \n",
       "\n",
       "   either  contains_perfect  \n",
       "0       0             False  \n",
       "1       0             False  \n",
       "2       0             False  \n",
       "3       0              True  \n",
       "4       0             False  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bb243fbe-ed0a-42e4-919d-f6996ffcd8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_15632\\751142716.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dataframe['constant'] = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 1, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 1, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0]], dtype=int64),\n",
       " array([ 1,  1,  1, ..., -1, -1, -1], dtype=int64))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_numpy_data(dataframe, features, label):\n",
    "    \"\"\"\n",
    "    Given a dataframe, a list of features (e.g. [‘sqft_living’, ‘bedrooms’]), to be used as inputs, and a name of the output\n",
    "    (e.g. ‘price’), return a feature matrix (i.e. a 2D array) consisting of first a column of ones followed by columns\n",
    "    containing the values of the input features in the data set in the same order as the input list. It also returns an\n",
    "    array of the values of the output in the data set (e.g. ‘price’).\n",
    "    \n",
    "    :param dataframe: the dataframe you want to convert to a numpy array\n",
    "    :param features: list of features (column names)\n",
    "    :param label: the name of the column you want to predict\n",
    "    :return: The feature matrix and the label array\n",
    "    \"\"\"\n",
    "    dataframe['constant'] = 1\n",
    "    features = ['constant'] + features\n",
    "    features_frame = dataframe[features]\n",
    "    feature_matrix = features_frame.values\n",
    "    label_sarray = dataframe[label]\n",
    "    label_array = label_sarray.values\n",
    "    return(feature_matrix, label_array)\n",
    "\n",
    "get_numpy_data(products, important_words,'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "53096a48-ce20-4680-a8ba-e57c8a5d9346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probability(feature_matrix, coefficients):\n",
    "    '''\n",
    "    produces probablistic estimate for P(y_i = +1 | x_i, w).\n",
    "    estimate ranges between 0 and 1.\n",
    "    '''\n",
    "    # Take dot product of feature_matrix and coefficients  \n",
    "    # YOUR CODE HERE\n",
    "    score = np.dot(feature_matrix, coefficients)\n",
    "    \n",
    "    # Compute P(y_i = +1 | x_i, w) using the link function\n",
    "    # YOUR CODE HERE\n",
    "    predictions = 1/(1+np.exp(-score))\n",
    "    \n",
    "    # return predictions\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fe6e4c30-ecab-4ce5-9755-4728b1f32f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):     \n",
    "    # Compute the dot product of errors and feature\n",
    "    derivative = np.dot(errors,feature)\n",
    "        # Return the derivative\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "628db98a-5452-4e8e-9e20-ecad6c068b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix, sentiment, coefficients):\n",
    "    indicator = (sentiment==+1)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    lp = np.sum((indicator-1)*scores - np.log(1. + np.exp(-scores)))\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4e218239-5d4d-4e31-b6ef-7b4c130b3db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter, plot=False):\n",
    "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
    "    if plot:\n",
    "        likelihood_list = []\n",
    "    for itr in range(max_iter):\n",
    "        # Predict P(y_i = +1|x_1,w) using your predict_probability() function\n",
    "        # YOUR CODE HERE\n",
    "        predictions = predict_probability(feature_matrix, coefficients)\n",
    "\n",
    "        # Compute indicator value for (y_i = +1)\n",
    "        indicator = (sentiment==+1)\n",
    "\n",
    "        # Compute the errors as indicator - predictions\n",
    "        errors = indicator - predictions\n",
    "\n",
    "        for j in range(len(coefficients)): \n",
    "            # loop over each coefficient\n",
    "            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j]\n",
    "            # compute the derivative for coefficients[j]. Save it in a variable called derivative\n",
    "            # YOUR CODE HERE\n",
    "            derivative = feature_derivative(errors, feature_matrix[:,j])\n",
    "\n",
    "            # add the step size times the derivative to the current coefficient\n",
    "            # YOUR CODE HERE\n",
    "            coefficients[j] += step_size*derivative\n",
    "            \n",
    "\n",
    "        # Checking whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood(feature_matrix, sentiment, coefficients)\n",
    "            if plot:\n",
    "                likelihood_list.append(compute_log_likelihood(feature_matrix, sentiment, coefficients))\n",
    "            else:\n",
    "                print ('iteration %*d: log likelihood of observed labels = %.8f' %(int(np.ceil(np.log10(max_iter))), itr, lp))\n",
    "    if plot:\n",
    "        x= [i for i in range(len(likelihood_list))]\n",
    "        plt.plot(x,likelihood_list,'ro')\n",
    "        plt.show()\n",
    "    if not plot:\n",
    "        return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "48ec0de6-546f-4c6d-9cbe-2d8c0a992fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -36780.91768478\n",
      "iteration   1: log likelihood of observed labels = -36775.13434712\n",
      "iteration   2: log likelihood of observed labels = -36769.35713564\n",
      "iteration   3: log likelihood of observed labels = -36763.58603240\n",
      "iteration   4: log likelihood of observed labels = -36757.82101962\n",
      "iteration   5: log likelihood of observed labels = -36752.06207964\n",
      "iteration   6: log likelihood of observed labels = -36746.30919497\n",
      "iteration   7: log likelihood of observed labels = -36740.56234821\n",
      "iteration   8: log likelihood of observed labels = -36734.82152213\n",
      "iteration   9: log likelihood of observed labels = -36729.08669961\n",
      "iteration  10: log likelihood of observed labels = -36723.35786366\n",
      "iteration  11: log likelihood of observed labels = -36717.63499744\n",
      "iteration  12: log likelihood of observed labels = -36711.91808422\n",
      "iteration  13: log likelihood of observed labels = -36706.20710739\n",
      "iteration  14: log likelihood of observed labels = -36700.50205049\n",
      "iteration  15: log likelihood of observed labels = -36694.80289716\n",
      "iteration  20: log likelihood of observed labels = -36666.39512033\n",
      "iteration  30: log likelihood of observed labels = -36610.01327118\n",
      "iteration  40: log likelihood of observed labels = -36554.19728365\n",
      "iteration  50: log likelihood of observed labels = -36498.93316099\n",
      "iteration  60: log likelihood of observed labels = -36444.20783914\n",
      "iteration  70: log likelihood of observed labels = -36390.00909449\n",
      "iteration  80: log likelihood of observed labels = -36336.32546144\n",
      "iteration  90: log likelihood of observed labels = -36283.14615871\n",
      "iteration 100: log likelihood of observed labels = -36230.46102347\n",
      "iteration 200: log likelihood of observed labels = -35728.89418769\n",
      "iteration 300: log likelihood of observed labels = -35268.51212683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 5.16220157e-03,  1.55656966e-02, -8.50204675e-03,  6.65460842e-02,\n",
       "        6.58907629e-02,  5.01743882e-03, -5.38601484e-02, -3.50488413e-03,\n",
       "        6.47945868e-02,  4.54356263e-02,  3.98353364e-03,  2.00775410e-02,\n",
       "        3.01350011e-02, -2.87115530e-02,  1.52161964e-02,  2.72592062e-04,\n",
       "        1.19448177e-02, -1.82461935e-02, -1.21706420e-02, -4.15110334e-02,\n",
       "        2.76820391e-03,  1.77031999e-02, -4.39700067e-03,  4.49764014e-02,\n",
       "        9.90916464e-03,  8.99239081e-04, -1.36219516e-03,  1.26859357e-02,\n",
       "        8.26466695e-03, -2.77426972e-02,  6.10128809e-04,  1.54084501e-02,\n",
       "       -1.32134753e-02, -3.00512492e-02,  2.97399371e-02,  1.84087080e-02,\n",
       "        2.86178752e-03, -1.05768015e-02, -6.57350362e-04, -1.01476555e-02,\n",
       "       -4.79579528e-03,  7.50891810e-03,  4.27938289e-03,  3.06785501e-03,\n",
       "       -2.20317661e-03,  9.57273354e-03,  9.91666827e-05, -1.98462567e-02,\n",
       "        1.75702722e-02,  1.55478612e-03, -1.77375440e-02,  9.78324102e-03,\n",
       "        1.17031606e-02, -7.35345937e-03, -6.08714030e-03,  6.43766808e-03,\n",
       "        1.07159665e-02, -3.05345476e-03,  7.17190727e-03,  5.73320003e-03,\n",
       "        4.60661876e-03, -5.20588421e-03,  6.71012331e-03,  9.03281814e-03,\n",
       "        1.74563147e-03,  6.00279979e-03,  1.20181744e-02, -1.83594607e-02,\n",
       "       -6.91010811e-03, -1.38687273e-02, -1.50406590e-02,  5.92353611e-03,\n",
       "        5.67478991e-03, -5.28786220e-03,  3.08147864e-03,  5.53751236e-03,\n",
       "        1.49917916e-02, -3.35666000e-04, -3.30695153e-02, -4.78990943e-03,\n",
       "       -6.41368859e-03,  7.99938935e-03, -8.61390444e-04,  1.68052959e-02,\n",
       "        1.32539901e-02,  1.72307051e-03,  2.98030675e-03,  8.58284300e-03,\n",
       "        1.17082481e-02,  2.80825907e-03,  2.18724016e-03,  1.68824711e-02,\n",
       "       -4.65973741e-03,  1.51368285e-03, -1.09509122e-02,  9.17842898e-03,\n",
       "       -1.88572281e-04, -3.89820373e-02, -2.44821005e-02, -1.87023714e-02,\n",
       "       -2.13943485e-02, -1.29690465e-02, -1.71378670e-02, -1.37566767e-02,\n",
       "       -1.49770449e-02, -5.10287978e-03, -2.89789761e-02, -1.48663194e-02,\n",
       "       -1.28088380e-02, -1.07709355e-02, -6.95286915e-03, -5.04082164e-03,\n",
       "       -9.25914404e-03, -2.40427481e-02, -2.65927785e-02, -1.97320937e-03,\n",
       "       -5.04127508e-03, -7.00791912e-03, -3.48088523e-03, -6.40958916e-03,\n",
       "       -4.07497010e-03, -6.30054296e-03, -1.09187932e-02, -1.26051900e-02,\n",
       "       -1.66895314e-03, -7.76418781e-03, -5.15960485e-04, -1.94199551e-03,\n",
       "       -1.24761586e-03, -5.01291731e-03, -9.12049191e-03, -7.22098801e-03,\n",
       "       -8.31782981e-03, -5.60573348e-03, -1.47098335e-02, -9.31520819e-03,\n",
       "       -2.22034402e-03, -7.07573098e-03, -5.10115608e-03, -8.93572862e-03,\n",
       "       -1.27545713e-02, -7.04171991e-03, -9.76219676e-04,  4.12091713e-04,\n",
       "        8.29251160e-04,  2.64661064e-03, -7.73228782e-03,  1.53471164e-03,\n",
       "       -7.37263060e-03, -3.73694386e-03, -3.81416409e-03, -1.64575145e-03,\n",
       "       -3.31887732e-03,  1.22257832e-03,  1.36699286e-05, -3.01866601e-03,\n",
       "       -1.02826343e-02, -1.06691327e-02,  2.23639046e-03, -9.87424798e-03,\n",
       "       -1.02192048e-02, -3.41330929e-03,  3.34489960e-03, -3.50984516e-03,\n",
       "       -6.26283150e-03, -7.22419943e-03, -5.47016154e-03, -1.25063947e-02,\n",
       "       -2.47805699e-03, -1.60017985e-02, -6.40098934e-03, -4.26644386e-03,\n",
       "       -1.55376990e-02,  2.31349237e-03, -9.06653337e-03, -6.30012672e-03,\n",
       "       -1.21010303e-02, -3.02578875e-03, -6.76289718e-03, -5.65498722e-03,\n",
       "       -6.87050239e-03, -1.18950595e-02, -1.86489236e-04, -1.15230476e-02,\n",
       "        2.81533219e-03, -8.10150295e-03, -1.00062131e-02,  4.02037651e-03,\n",
       "       -5.44300346e-03,  2.85818985e-03,  1.19885003e-04, -6.47587687e-03,\n",
       "       -1.14493516e-03, -7.09205934e-03])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the feature matrix for the sentiment column.\n",
    "feature_matrix,sentiment = get_numpy_data(products, important_words,'sentiment')\n",
    "logistic_regression(feature_matrix, sentiment, np.zeros(194), 1e-7, 301)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee72458b-4e0a-4c68-94bc-28dce9977ff9",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc342895-b21a-4816-8861-aee6055c6b74",
   "metadata": {},
   "source": [
    "> Question 1\n",
    "> \n",
    "> How many reviews in **amazon_baby_subset.gl** contain the word **perfect**?\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "85ec49ba-b7c9-4afb-a4bb-be5780971f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2955"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting the number of rows in the dataframe that have a value greater than 0 in the column 'contains_perfect'.\n",
    "products['contains_perfect'] = products['perfect'] >=1\n",
    "(products['contains_perfect']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80122852-c63f-49b9-b032-95c82be9030d",
   "metadata": {},
   "source": [
    "> Question 2\n",
    "> \n",
    "> Consider the **feature_matrix** that was obtained by converting our data to NumPy format.\n",
    "> \n",
    "> How many features are there in the **feature_matrix**?\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fec95240-7068-41cf-9473-69108a8d388e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the feature matrix for the sentiment column.\n",
    "feature_matrix,_ = get_numpy_data(products, important_words,'sentiment')\n",
    "# Getting the number of columns in the feature matrix.\n",
    "feature_matrix.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f095c98a-88a9-4a5f-9677-c84456df70b2",
   "metadata": {},
   "source": [
    "> Question 3\n",
    "> \n",
    "> Assuming that the intercept is present, how does the number of features in **feature_matrix** relate to the number of features in the logistic regression model? \n",
    ">\n",
    "> Let x = [number of features in feature_matrix] and y = [number of features in logistic regression model]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "aff081fc-d10e-4563-bfcd-afaac427461e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x == y+1\n",
    "feature_matrix.shape[1] == weights.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918c40c2-42ac-47af-89d0-f25bc2c3b290",
   "metadata": {},
   "source": [
    "> Question 4\n",
    "> \n",
    "> Run your logistic regression solver with provided parameters.\n",
    "> \n",
    "> As each iteration of gradient ascent passes, does the log-likelihood increase or decrease?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "98bf1a83-d0db-4196-b929-fdeff0175bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Getting the feature matrix for the sentiment column.\n",
    "feature_matrix,sentiment = get_numpy_data(products, important_words,'sentiment')\n",
    "# Training the model\n",
    "logistic_regression(feature_matrix, sentiment, np.zeros(194), 1e-7, 301, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dac20f-ea4b-45b5-981d-131cec0dda32",
   "metadata": {},
   "source": [
    "> Question 5\n",
    "> \n",
    "> We make predictions using the weights just learned.\n",
    "> \n",
    "> How many reviews were predicted to have positive sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fd11dc71-45cc-4362-bcac-ce8956492155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -36780.91768478\n",
      "iteration   1: log likelihood of observed labels = -36775.13434712\n",
      "iteration   2: log likelihood of observed labels = -36769.35713564\n",
      "iteration   3: log likelihood of observed labels = -36763.58603240\n",
      "iteration   4: log likelihood of observed labels = -36757.82101962\n",
      "iteration   5: log likelihood of observed labels = -36752.06207964\n",
      "iteration   6: log likelihood of observed labels = -36746.30919497\n",
      "iteration   7: log likelihood of observed labels = -36740.56234821\n",
      "iteration   8: log likelihood of observed labels = -36734.82152213\n",
      "iteration   9: log likelihood of observed labels = -36729.08669961\n",
      "iteration  10: log likelihood of observed labels = -36723.35786366\n",
      "iteration  11: log likelihood of observed labels = -36717.63499744\n",
      "iteration  12: log likelihood of observed labels = -36711.91808422\n",
      "iteration  13: log likelihood of observed labels = -36706.20710739\n",
      "iteration  14: log likelihood of observed labels = -36700.50205049\n",
      "iteration  15: log likelihood of observed labels = -36694.80289716\n",
      "iteration  20: log likelihood of observed labels = -36666.39512033\n",
      "iteration  30: log likelihood of observed labels = -36610.01327118\n",
      "iteration  40: log likelihood of observed labels = -36554.19728365\n",
      "iteration  50: log likelihood of observed labels = -36498.93316099\n",
      "iteration  60: log likelihood of observed labels = -36444.20783914\n",
      "iteration  70: log likelihood of observed labels = -36390.00909449\n",
      "iteration  80: log likelihood of observed labels = -36336.32546144\n",
      "iteration  90: log likelihood of observed labels = -36283.14615871\n",
      "iteration 100: log likelihood of observed labels = -36230.46102347\n",
      "iteration 200: log likelihood of observed labels = -35728.89418769\n",
      "iteration 300: log likelihood of observed labels = -35268.51212683\n",
      "Number of positive predictions : 25126\n"
     ]
    }
   ],
   "source": [
    "# # Getting the feature matrix for the sentiment column.\n",
    "feature_matrix,sentiment = get_numpy_data(products, important_words,'sentiment')\n",
    "# Training the model\n",
    "weights = logistic_regression(feature_matrix, sentiment, np.zeros(194), 1e-7, 301)\n",
    "print(\"Number of positive predictions :\", np.sum(np.dot(feature_matrix, weights)>0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e45d1-829f-4f2a-8229-7c98e4c402a6",
   "metadata": {},
   "source": [
    "> Question 6\n",
    "> \n",
    "> What is the accuracy of the model on predictions made above? (round to 2 digits of accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "63f3bb67-9659-449f-934d-14d4831191ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score is  0.7518653904130238\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "pred = (np.dot(feature_matrix, weights)>0).astype(int)\n",
    "actual = (sentiment>0).astype(int)\n",
    "print(\"Accuracy Score is \",(pred == actual).sum()/ pred.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e74fc1-dbf2-4d7d-a5f3-611c3a11c87f",
   "metadata": {},
   "source": [
    "> Question 7\n",
    "> \n",
    "> We look at \"most positive\" words, the words that correspond most strongly with positive reviews.\n",
    "> \n",
    "> Which of the following words is **not** present in the top 10 \"most positive\" words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3ab5894d-7e41-4633-aeac-fd62fda6c4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('great', 0.0665460841704577), ('love', 0.06589076292212326), ('easy', 0.0647945868025784), ('little', 0.04543562630842137), ('loves', 0.04497640139490604), ('well', 0.030135001092107077), ('perfect', 0.029739937104968462), ('old', 0.02007754103477538), ('nice', 0.018408707995268992), ('daughter', 0.017703199905701697), ('soft', 0.017570272245602887)]\n"
     ]
    }
   ],
   "source": [
    "zipped_name_weights = list(zip(['constant'] + important_words, weights))\n",
    "zipped_name_weights.sort(key= lambda x:x[1],reverse=True)\n",
    "print(zipped_name_weights[0:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75685c9a-8cb2-4dac-9dea-407bc29b3b05",
   "metadata": {},
   "source": [
    "> Question 8\n",
    "> \n",
    "> Similarly, we look at \"most negative\" words, the words that correspond most strongly with negative reviews.\n",
    "> \n",
    "> Which of the following words is **not** present in the top 10 \"most negative\" words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6e9d3fdf-0114-4ca1-896c-70e32ba4eb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('would', -0.053860148445203135), ('product', -0.0415110333921089), ('money', -0.03898203728648711), ('work', -0.03306951529475272), ('even', -0.030051249236035808), ('disappointed', -0.028978976142317068), ('get', -0.02871155298019258), ('back', -0.027742697230661327), ('return', -0.026592778462247283), ('monitor', -0.024482100545891717)]\n"
     ]
    }
   ],
   "source": [
    "zipped_name_weights = list(zip(['constant'] + important_words, weights))\n",
    "zipped_name_weights.sort(key= lambda x:x[1])\n",
    "print(zipped_name_weights[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1992ac-f657-47f9-bf27-be9b4de17793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
