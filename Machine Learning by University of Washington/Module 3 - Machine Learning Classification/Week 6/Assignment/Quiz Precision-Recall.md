## Precision-Recall
> 
> Total points 9
> 
> ### 1.
> 
> Question 1
> 
> Questions 1 to 5 refer to the following scenario:
> 
> Suppose a binary classifier produced the following confusion matrix.
> 
> **Predicted Positive**
> 
> **Predicted Negative**
> 
> **Actual Positive**
> 
> 5600
> 
> 40
> 
> **Actual Negative**
> 
> 1900
> 
> 2460
> 
> What is the **accuracy** of this classifier? Round your answer to 2 decimal places.
> 
> 1 point
> 

     0.81
> 
> ### 2.
> 
> Question 2
> 
> Refer to the scenario presented in Question 1 to answer the following:
> 
> (True/False) This classifier is better than random guessing.
> 
> 1 point
> 

      True 
> 
>  False 
> 
> ### 3.
> 
> Question 3
> 
> Refer to the scenario presented in Question 1 to answer the following:
> 
> (True/False) This classifier is better than the majority class classifier.
> 
> 1 point
> 

      True 
> 
>  False 
> 
> ### 4.
> 
> Question 4
> 
> Refer to the scenario presented in Question 1 to answer the following:
> 
> Which of the following points in the precision-recall space corresponds to this classifier?
> 
> ![](https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/TDEYl-BmEeWuUgrcWIxPhQ_3c704bfa2b87d7dc0429d29ac709c690_Capture.PNG?expiry=1656374400000&hmac=1124vh6SUe1ncOVQ_MYhoFSmrMmLijeuhp3GfP1SuBY)
> 
> 1 point
> 
>  (1) 
> 
>  (2) 
> 

      (3) 
> 
>  (4) 
> 
>  (5) 
> 
> ### 5.
> 
> Question 5
> 
> Refer to the scenario presented in Question 1 to answer the following:
> 
> Which of the following best describes this classifier?
> 
> 1 point
> 

      It is optimistic 
> 
>  It is pessimistic 
> 
>  None of the above 
> 
> ### 6.
> 
> Question 6
> 
> Suppose we are fitting a logistic regression model on a dataset where the vast majority of the data points are labeled as positive. To compensate for overfitting to the dominant class, we should
> 
> 1 point
> 

      Require higher confidence level for positive predictions 
> 
>  Require lower confidence level for positive predictions 
> 
> ### 7.
> 
> Question 7
> 
> It is often the case that false positives and false negatives incur different costs. In situations where false negatives cost much more than false positives, we should
> 
> 1 point
> 
>  Require higher confidence level for positive predictions 
> 

      Require lower confidence level for positive predictions 
> 
> ### 8.
> 
> Question 8
> 
> We are interested in reducing the number of false negatives. Which of the following metrics should we primarily look at?
> 
> 1 point
> 
>  Accuracy 
> 
>  Precision 
> 

      Recall 
> 
> ### 9.
> 
> Question 9
> 
> Suppose we set the threshold for positive predictions at 0.9\. What is the lowest score that is classified as positive? Round your answer to 2 decimal places.
> 
> 1 point
> 

     0.9
>
> -- https://www.coursera.org/learn/ml-classification/exam/pGfWZ/precision-recall/attempt#TUNNELVISIONWRAPPER_CONTENT_ID
