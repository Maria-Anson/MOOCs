{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5feafac6-f5db-4386-9b06-604f7ac0b80a",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f9adfad-41b4-4bd6-b0c5-adc8a26b823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40ed0d88-2ef0-4aa5-b4a4-4d44d4a4013f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the csv file and displaying the first 5 rows of the dataframe.\n",
    "products = pd.read_csv(r'Dataset/amazon_baby.csv')\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93374d15-e218-418a-af95-a9cc150a8923",
   "metadata": {},
   "source": [
    "## Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0919360f-ab8e-4eab-bf13-640725819c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "      <td>These flannel wipes are OK but in my opinion n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a product well worth the purchase  I h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  These flannel wipes are OK, but in my opinion ...       3   \n",
       "1  it came early and was not disappointed. i love...       5   \n",
       "2  Very soft and comfortable and warmer than it l...       5   \n",
       "3  This is a product well worth the purchase.  I ...       5   \n",
       "4  All of my kids have cried non-stop when I trie...       5   \n",
       "\n",
       "                                        review_clean  \n",
       "0  These flannel wipes are OK but in my opinion n...  \n",
       "1  it came early and was not disappointed i love ...  \n",
       "2  Very soft and comfortable and warmer than it l...  \n",
       "3  This is a product well worth the purchase  I h...  \n",
       "4  All of my kids have cried nonstop when I tried...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    \"\"\"\n",
    "    The function takes in a string, and returns a new string with all of the punctuation removed. \n",
    "    \n",
    "    The function uses Python's built-in string.punctuation variable, which is a string of all the punctuation characters. \n",
    "    \n",
    "    The function str.translate() takes in a translation table, which you can generate using the maketrans() helper function\n",
    "    in the string library. \n",
    "    \n",
    "    :param text: The text to be processed\n",
    "    :return: A string with all punctuation removed.\n",
    "    \"\"\"\n",
    "    import string\n",
    "    return str(text).translate(str.maketrans('', '', string.punctuation)) \n",
    "\n",
    "# Applying the remove_punctuation function to the review column of the products dataframe.\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)\n",
    "\n",
    "# Displaying the first 5 rows of the dataframe.\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d9120c5-18b4-4723-8e90-7e2678304e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a9a8c6b-a840-499c-b81c-7588b0550f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code is loading the train and test index files into the train_index and test_index variables.Index files are used to follow the same implementation done in assignment as it's not done on pandas.\n",
    "import json\n",
    "\n",
    "temp_file = open('Dataset/module-9-assignment-train-idx.json')\n",
    "train_index = json.load(temp_file)\n",
    "temp_file.close()\n",
    "temp_file = open('Dataset/module-9-assignment-test-idx.json')\n",
    "test_index = json.load(temp_file)\n",
    "temp_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50d3a4b0-ed7a-4616-b583-ddaed8661f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above code is splitting the data into training and test data.\n",
    "train_data = products.iloc[train_index]\n",
    "test_data = products.iloc[test_index]\n",
    "# Reseting the index\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)\n",
    "# Assigning the sentiment column to the train_target and test_target variables.\n",
    "train_target = train_data['sentiment']\n",
    "test_target = test_data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75f459c8-36f9-4e24-9653-d437242f307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "# Use this token pattern to keep single-letter words\n",
    "# First, learn vocabulary from the training data and assign columns to words\n",
    "# Then convert the training data into a sparse matrix\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b0a3bf2-ac2e-4ac5-afb1-b0ec35167864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.8836393088552916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "model = LogisticRegression().fit(train_matrix, train_target)\n",
    "\n",
    "print (\"Test Accuracy: \", metrics.accuracy_score(model.predict(test_matrix),test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f17c390e-1ac4-49a9-9a79-2d68e73ced7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pr_curve(precision, recall, title):\n",
    "    plt.rcParams['figure.figsize'] = 7, 5\n",
    "    plt.locator_params(axis = 'x', nbins = 5)\n",
    "    plt.plot(precision, recall, 'b-', linewidth=4.0, color = '#B0017F')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Precision')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f3c2b4-9fbd-42f0-8184-1c4d9b2e5d82",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547bf09a-3c28-4055-87d8-28935e3d1faf",
   "metadata": {},
   "source": [
    "> Question 1\n",
    "> \n",
    "> Consider the logistic regression model trained on **amazon_baby.sframe** using Turi Create.\n",
    "> \n",
    "> Using accuracy as the evaluation metric, was our **logistic regression model** better than the **majority class classifier**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11f0c348-6954-4681-ae85-fe262cdd9af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of model:  0.8836393088552916\n",
      "Test Accuracy of majority classifier model:  0.7642788576913847\n"
     ]
    }
   ],
   "source": [
    "print (\"Test Accuracy of model: \", metrics.accuracy_score(model.predict(test_matrix),test_target))\n",
    "majority_class = train_target.value_counts().head(1).index.values[0]\n",
    "print (\"Test Accuracy of majority classifier model: \", metrics.accuracy_score(np.array([majority_class]*len(test_target)),test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d86684-f63a-4630-9a1e-c164fbbb5837",
   "metadata": {},
   "source": [
    "> Question 2\n",
    "> \n",
    "> How many predicted values in the **test set** are **false positives**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ceba6aed-2ea6-4774-99a5-8193f76ed024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5468,  2390],\n",
       "       [ 1489, 23989]], dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(test_target, model.predict(test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a950d35-c47a-42ed-91bb-743cc439d9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics.plot_confusion_matrix(model,test_matrix,test_target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d2b774-f9d0-4339-83bb-4ad671d875e4",
   "metadata": {},
   "source": [
    "> Question 3\n",
    "> \n",
    "> Consider the scenario where each false positive costs 100 and each false negative 1.\n",
    "> \n",
    "> Given the stipulation, what is the cost associated with the logistic regression classifier's performance on the **test set**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aa75a33d-fe41-45c5-8fab-842367143e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240489"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_mt = metrics.confusion_matrix(model.predict(test_matrix),test_target)\n",
    "false_positive = cm_mt[1,0]\n",
    "false_negative = cm_mt[0,1]\n",
    "100*false_positive+false_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2120e6b0-9b6e-4c5c-ace5-a598aad92cd3",
   "metadata": {},
   "source": [
    "> Question 4\n",
    "> \n",
    "> Out of all reviews in the **test set** that are predicted to be positive, what fraction of them are **false positives**? (Round to the second decimal place e.g. 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d717361c-b99f-44dd-bacb-783314e698bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09060237309981424"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive/cm_mt[1].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75398e04-544f-4674-8d33-6c4eb1c6ad4e",
   "metadata": {},
   "source": [
    "> Question 6\n",
    "> \n",
    "> What fraction of the positive reviews in the **test_set** were correctly predicted as positive by the classifier? Round your answer to 2 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "537d883c-f27c-4993-9a86-8645eba4b578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.941557422089646"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(test_matrix[test_target==1])==1).sum() / test_target[test_target==1].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e112f2fe-a1b0-4ee6-8a38-b13cbc2ff07c",
   "metadata": {},
   "source": [
    "> Question 7\n",
    "> \n",
    "> What is the recall value for a classifier that predicts **+1** for all data points in the **test_data**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e7dce74b-db40-4554-878e-99d569cc2f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(test_target,np.array([1.]*len(test_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28394404-e719-4032-859b-65dbf161689e",
   "metadata": {},
   "source": [
    "> Question 10\n",
    "> \n",
    "> Among all the threshold values tried, what is the **smallest** threshold value that achieves a precision of 96.5% or better? Round your answer to 3 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "599503e4-29c2-47ff-853c-4b4b6394d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.predict_proba(test_matrix)[:,1]\n",
    "\n",
    "predictions[predictions==0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "03d3deb4-95ff-4e7e-b8ec-3b6d6d3dbbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.5 : Precsion 0.909 : Recall 0.942\n",
      "Threshold 0.505 : Precsion 0.91 : Recall 0.941\n",
      "Threshold 0.51 : Precsion 0.911 : Recall 0.94\n",
      "Threshold 0.515 : Precsion 0.912 : Recall 0.94\n",
      "Threshold 0.52 : Precsion 0.913 : Recall 0.939\n",
      "Threshold 0.525 : Precsion 0.913 : Recall 0.938\n",
      "Threshold 0.53 : Precsion 0.914 : Recall 0.937\n",
      "Threshold 0.535 : Precsion 0.915 : Recall 0.936\n",
      "Threshold 0.54 : Precsion 0.916 : Recall 0.936\n",
      "Threshold 0.545 : Precsion 0.917 : Recall 0.935\n",
      "Threshold 0.551 : Precsion 0.918 : Recall 0.934\n",
      "Threshold 0.556 : Precsion 0.918 : Recall 0.934\n",
      "Threshold 0.561 : Precsion 0.919 : Recall 0.933\n",
      "Threshold 0.566 : Precsion 0.92 : Recall 0.931\n",
      "Threshold 0.571 : Precsion 0.92 : Recall 0.931\n",
      "Threshold 0.576 : Precsion 0.921 : Recall 0.929\n",
      "Threshold 0.581 : Precsion 0.922 : Recall 0.928\n",
      "Threshold 0.586 : Precsion 0.922 : Recall 0.927\n",
      "Threshold 0.591 : Precsion 0.923 : Recall 0.926\n",
      "Threshold 0.596 : Precsion 0.924 : Recall 0.925\n",
      "Threshold 0.601 : Precsion 0.924 : Recall 0.924\n",
      "Threshold 0.606 : Precsion 0.925 : Recall 0.923\n",
      "Threshold 0.611 : Precsion 0.926 : Recall 0.922\n",
      "Threshold 0.616 : Precsion 0.926 : Recall 0.921\n",
      "Threshold 0.621 : Precsion 0.927 : Recall 0.919\n",
      "Threshold 0.626 : Precsion 0.927 : Recall 0.918\n",
      "Threshold 0.631 : Precsion 0.928 : Recall 0.917\n",
      "Threshold 0.636 : Precsion 0.928 : Recall 0.916\n",
      "Threshold 0.641 : Precsion 0.929 : Recall 0.914\n",
      "Threshold 0.646 : Precsion 0.93 : Recall 0.913\n",
      "Threshold 0.652 : Precsion 0.93 : Recall 0.912\n",
      "Threshold 0.657 : Precsion 0.931 : Recall 0.91\n",
      "Threshold 0.662 : Precsion 0.931 : Recall 0.908\n",
      "Threshold 0.667 : Precsion 0.932 : Recall 0.907\n",
      "Threshold 0.672 : Precsion 0.933 : Recall 0.906\n",
      "Threshold 0.677 : Precsion 0.933 : Recall 0.904\n",
      "Threshold 0.682 : Precsion 0.934 : Recall 0.903\n",
      "Threshold 0.687 : Precsion 0.934 : Recall 0.901\n",
      "Threshold 0.692 : Precsion 0.935 : Recall 0.9\n",
      "Threshold 0.697 : Precsion 0.935 : Recall 0.898\n",
      "Threshold 0.702 : Precsion 0.936 : Recall 0.896\n",
      "Threshold 0.707 : Precsion 0.936 : Recall 0.894\n",
      "Threshold 0.712 : Precsion 0.937 : Recall 0.893\n",
      "Threshold 0.717 : Precsion 0.938 : Recall 0.89\n",
      "Threshold 0.722 : Precsion 0.938 : Recall 0.889\n",
      "Threshold 0.727 : Precsion 0.939 : Recall 0.887\n",
      "Threshold 0.732 : Precsion 0.94 : Recall 0.885\n",
      "Threshold 0.737 : Precsion 0.941 : Recall 0.883\n",
      "Threshold 0.742 : Precsion 0.942 : Recall 0.881\n",
      "Threshold 0.747 : Precsion 0.942 : Recall 0.879\n",
      "Threshold 0.753 : Precsion 0.943 : Recall 0.877\n",
      "Threshold 0.758 : Precsion 0.943 : Recall 0.874\n",
      "Threshold 0.763 : Precsion 0.944 : Recall 0.872\n",
      "Threshold 0.768 : Precsion 0.945 : Recall 0.869\n",
      "Threshold 0.773 : Precsion 0.945 : Recall 0.867\n",
      "Threshold 0.778 : Precsion 0.946 : Recall 0.864\n",
      "Threshold 0.783 : Precsion 0.946 : Recall 0.861\n",
      "Threshold 0.788 : Precsion 0.947 : Recall 0.858\n",
      "Threshold 0.793 : Precsion 0.948 : Recall 0.854\n",
      "Threshold 0.798 : Precsion 0.948 : Recall 0.851\n",
      "Threshold 0.803 : Precsion 0.949 : Recall 0.848\n",
      "Threshold 0.808 : Precsion 0.95 : Recall 0.845\n",
      "Threshold 0.813 : Precsion 0.95 : Recall 0.842\n",
      "Threshold 0.818 : Precsion 0.951 : Recall 0.838\n",
      "Threshold 0.823 : Precsion 0.952 : Recall 0.835\n",
      "Threshold 0.828 : Precsion 0.952 : Recall 0.831\n",
      "Threshold 0.833 : Precsion 0.953 : Recall 0.827\n",
      "Threshold 0.838 : Precsion 0.954 : Recall 0.823\n",
      "Threshold 0.843 : Precsion 0.955 : Recall 0.819\n",
      "Threshold 0.848 : Precsion 0.956 : Recall 0.814\n",
      "Threshold 0.854 : Precsion 0.957 : Recall 0.809\n",
      "Threshold 0.859 : Precsion 0.957 : Recall 0.804\n",
      "Threshold 0.864 : Precsion 0.958 : Recall 0.799\n",
      "Threshold 0.869 : Precsion 0.959 : Recall 0.794\n",
      "Threshold 0.874 : Precsion 0.96 : Recall 0.788\n",
      "Threshold 0.879 : Precsion 0.962 : Recall 0.778\n",
      "Threshold 0.884 : Precsion 0.963 : Recall 0.771\n",
      "Threshold 0.889 : Precsion 0.963 : Recall 0.765\n",
      "Threshold 0.894 : Precsion 0.964 : Recall 0.758\n",
      "Threshold 0.899 : Precsion 0.965 : Recall 0.75\n",
      "Threshold 0.904 : Precsion 0.966 : Recall 0.742\n",
      "Threshold 0.909 : Precsion 0.967 : Recall 0.734\n",
      "Threshold 0.914 : Precsion 0.968 : Recall 0.726\n",
      "Threshold 0.919 : Precsion 0.969 : Recall 0.716\n",
      "Threshold 0.924 : Precsion 0.97 : Recall 0.706\n",
      "Threshold 0.929 : Precsion 0.971 : Recall 0.694\n",
      "Threshold 0.934 : Precsion 0.973 : Recall 0.682\n",
      "Threshold 0.939 : Precsion 0.974 : Recall 0.668\n",
      "Threshold 0.944 : Precsion 0.975 : Recall 0.654\n",
      "Threshold 0.949 : Precsion 0.976 : Recall 0.638\n",
      "Threshold 0.955 : Precsion 0.976 : Recall 0.619\n",
      "Threshold 0.96 : Precsion 0.978 : Recall 0.599\n",
      "Threshold 0.965 : Precsion 0.978 : Recall 0.578\n",
      "Threshold 0.97 : Precsion 0.979 : Recall 0.552\n",
      "Threshold 0.975 : Precsion 0.98 : Recall 0.52\n",
      "Threshold 0.98 : Precsion 0.981 : Recall 0.484\n",
      "Threshold 0.985 : Precsion 0.983 : Recall 0.436\n",
      "Threshold 0.99 : Precsion 0.984 : Recall 0.375\n",
      "Threshold 0.995 : Precsion 0.986 : Recall 0.287\n",
      "Threshold 1.0 : Precsion 0.0 : Recall 0.0\n"
     ]
    }
   ],
   "source": [
    "threshold_values = np.linspace(0.5, 1, num=100)\n",
    "for threshold in threshold_values:\n",
    "    predictions = (probabilities>threshold).astype(int)\n",
    "    predictions[predictions==0] = -1\n",
    "    print(\"Threshold {} : Precsion {} : Recall {}\".format(threshold.round(3), metrics.precision_score(test_target,predictions).round(3), metrics.recall_score(test_target,predictions).round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c496606-7dbb-4c38-8fbc-985e9bf34729",
   "metadata": {},
   "source": [
    "> Question 11\n",
    "> \n",
    "> Using threshold = 0.98, how many **false negatives** do we get on the **test_data**? (**Hint**: You may use the turicreate.evaluation.confusion_matrix function implemented in Turi Create.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8521bb84-88e4-46d6-89a8-9148493403c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7625,   233],\n",
       "       [13181, 12297]], dtype=int64)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = (probabilities>0.98).astype(int)\n",
    "predictions[predictions==0] = -1\n",
    "metrics.confusion_matrix(test_target, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faa497a-37aa-440f-9f53-194ff4847d17",
   "metadata": {},
   "source": [
    "> Question 12\n",
    "> \n",
    "> Questions 13 and 14 are concerned with the reviews that contain the word **baby**.\n",
    "> \n",
    "> Among all the threshold values tried, what is the **smallest** threshold value that achieves a precision of 96.5% or better for the reviews of data in **baby_reviews**? Round your answer to 3 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e517a574-a0e8-4b3c-9017-e9038fc0912a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.5 : Precsion 0.911 : Recall 0.942\n",
      "Threshold 0.505 : Precsion 0.913 : Recall 0.941\n",
      "Threshold 0.51 : Precsion 0.914 : Recall 0.94\n",
      "Threshold 0.515 : Precsion 0.915 : Recall 0.94\n",
      "Threshold 0.52 : Precsion 0.916 : Recall 0.939\n",
      "Threshold 0.525 : Precsion 0.916 : Recall 0.937\n",
      "Threshold 0.53 : Precsion 0.917 : Recall 0.937\n",
      "Threshold 0.535 : Precsion 0.917 : Recall 0.936\n",
      "Threshold 0.54 : Precsion 0.918 : Recall 0.936\n",
      "Threshold 0.545 : Precsion 0.919 : Recall 0.935\n",
      "Threshold 0.551 : Precsion 0.92 : Recall 0.934\n",
      "Threshold 0.556 : Precsion 0.921 : Recall 0.934\n",
      "Threshold 0.561 : Precsion 0.922 : Recall 0.932\n",
      "Threshold 0.566 : Precsion 0.923 : Recall 0.93\n",
      "Threshold 0.571 : Precsion 0.923 : Recall 0.93\n",
      "Threshold 0.576 : Precsion 0.924 : Recall 0.928\n",
      "Threshold 0.581 : Precsion 0.924 : Recall 0.928\n",
      "Threshold 0.586 : Precsion 0.925 : Recall 0.927\n",
      "Threshold 0.591 : Precsion 0.926 : Recall 0.926\n",
      "Threshold 0.596 : Precsion 0.927 : Recall 0.925\n",
      "Threshold 0.601 : Precsion 0.927 : Recall 0.923\n",
      "Threshold 0.606 : Precsion 0.928 : Recall 0.922\n",
      "Threshold 0.611 : Precsion 0.928 : Recall 0.921\n",
      "Threshold 0.616 : Precsion 0.929 : Recall 0.919\n",
      "Threshold 0.621 : Precsion 0.929 : Recall 0.919\n",
      "Threshold 0.626 : Precsion 0.929 : Recall 0.917\n",
      "Threshold 0.631 : Precsion 0.929 : Recall 0.916\n",
      "Threshold 0.636 : Precsion 0.93 : Recall 0.915\n",
      "Threshold 0.641 : Precsion 0.93 : Recall 0.914\n",
      "Threshold 0.646 : Precsion 0.931 : Recall 0.913\n",
      "Threshold 0.652 : Precsion 0.932 : Recall 0.912\n",
      "Threshold 0.657 : Precsion 0.932 : Recall 0.91\n",
      "Threshold 0.662 : Precsion 0.932 : Recall 0.907\n",
      "Threshold 0.667 : Precsion 0.933 : Recall 0.906\n",
      "Threshold 0.672 : Precsion 0.933 : Recall 0.906\n",
      "Threshold 0.677 : Precsion 0.934 : Recall 0.904\n",
      "Threshold 0.682 : Precsion 0.934 : Recall 0.901\n",
      "Threshold 0.687 : Precsion 0.935 : Recall 0.901\n",
      "Threshold 0.692 : Precsion 0.936 : Recall 0.899\n",
      "Threshold 0.697 : Precsion 0.936 : Recall 0.897\n",
      "Threshold 0.702 : Precsion 0.936 : Recall 0.896\n",
      "Threshold 0.707 : Precsion 0.937 : Recall 0.892\n",
      "Threshold 0.712 : Precsion 0.937 : Recall 0.891\n",
      "Threshold 0.717 : Precsion 0.938 : Recall 0.889\n",
      "Threshold 0.722 : Precsion 0.939 : Recall 0.887\n",
      "Threshold 0.727 : Precsion 0.94 : Recall 0.886\n",
      "Threshold 0.732 : Precsion 0.942 : Recall 0.884\n",
      "Threshold 0.737 : Precsion 0.943 : Recall 0.882\n",
      "Threshold 0.742 : Precsion 0.943 : Recall 0.881\n",
      "Threshold 0.747 : Precsion 0.943 : Recall 0.878\n",
      "Threshold 0.753 : Precsion 0.944 : Recall 0.875\n",
      "Threshold 0.758 : Precsion 0.944 : Recall 0.873\n",
      "Threshold 0.763 : Precsion 0.944 : Recall 0.87\n",
      "Threshold 0.768 : Precsion 0.945 : Recall 0.866\n",
      "Threshold 0.773 : Precsion 0.946 : Recall 0.863\n",
      "Threshold 0.778 : Precsion 0.946 : Recall 0.86\n",
      "Threshold 0.783 : Precsion 0.946 : Recall 0.856\n",
      "Threshold 0.788 : Precsion 0.947 : Recall 0.853\n",
      "Threshold 0.793 : Precsion 0.947 : Recall 0.85\n",
      "Threshold 0.798 : Precsion 0.947 : Recall 0.846\n",
      "Threshold 0.803 : Precsion 0.948 : Recall 0.842\n",
      "Threshold 0.808 : Precsion 0.948 : Recall 0.838\n",
      "Threshold 0.813 : Precsion 0.949 : Recall 0.835\n",
      "Threshold 0.818 : Precsion 0.95 : Recall 0.83\n",
      "Threshold 0.823 : Precsion 0.95 : Recall 0.827\n",
      "Threshold 0.828 : Precsion 0.951 : Recall 0.824\n",
      "Threshold 0.833 : Precsion 0.952 : Recall 0.819\n",
      "Threshold 0.838 : Precsion 0.953 : Recall 0.815\n",
      "Threshold 0.843 : Precsion 0.954 : Recall 0.809\n",
      "Threshold 0.848 : Precsion 0.955 : Recall 0.804\n",
      "Threshold 0.854 : Precsion 0.956 : Recall 0.8\n",
      "Threshold 0.859 : Precsion 0.957 : Recall 0.796\n",
      "Threshold 0.864 : Precsion 0.957 : Recall 0.791\n",
      "Threshold 0.869 : Precsion 0.958 : Recall 0.786\n",
      "Threshold 0.874 : Precsion 0.959 : Recall 0.779\n",
      "Threshold 0.879 : Precsion 0.962 : Recall 0.769\n",
      "Threshold 0.884 : Precsion 0.963 : Recall 0.762\n",
      "Threshold 0.889 : Precsion 0.963 : Recall 0.756\n",
      "Threshold 0.894 : Precsion 0.965 : Recall 0.748\n",
      "Threshold 0.899 : Precsion 0.966 : Recall 0.738\n",
      "Threshold 0.904 : Precsion 0.966 : Recall 0.73\n",
      "Threshold 0.909 : Precsion 0.967 : Recall 0.721\n",
      "Threshold 0.914 : Precsion 0.968 : Recall 0.714\n",
      "Threshold 0.919 : Precsion 0.969 : Recall 0.704\n",
      "Threshold 0.924 : Precsion 0.971 : Recall 0.696\n",
      "Threshold 0.929 : Precsion 0.972 : Recall 0.683\n",
      "Threshold 0.934 : Precsion 0.975 : Recall 0.67\n",
      "Threshold 0.939 : Precsion 0.976 : Recall 0.656\n",
      "Threshold 0.944 : Precsion 0.977 : Recall 0.643\n",
      "Threshold 0.949 : Precsion 0.978 : Recall 0.625\n",
      "Threshold 0.955 : Precsion 0.977 : Recall 0.605\n",
      "Threshold 0.96 : Precsion 0.979 : Recall 0.584\n",
      "Threshold 0.965 : Precsion 0.981 : Recall 0.566\n",
      "Threshold 0.97 : Precsion 0.982 : Recall 0.54\n",
      "Threshold 0.975 : Precsion 0.983 : Recall 0.51\n",
      "Threshold 0.98 : Precsion 0.983 : Recall 0.472\n",
      "Threshold 0.985 : Precsion 0.982 : Recall 0.429\n",
      "Threshold 0.99 : Precsion 0.986 : Recall 0.368\n",
      "Threshold 0.995 : Precsion 0.987 : Recall 0.277\n",
      "Threshold 1.0 : Precsion 0.0 : Recall 0.0\n"
     ]
    }
   ],
   "source": [
    "baby_index = test_data['name'].fillna('').str.lower().apply(lambda x : 1 if 'baby' in x else 0).astype('bool')\n",
    "baby_reviews = test_data[baby_index]\n",
    "baby_matrix = vectorizer.transform(baby_reviews['review_clean'])\n",
    "probabilities = model.predict_proba(baby_matrix)[:,1]\n",
    "baby_target = baby_reviews['sentiment']\n",
    "for threshold in threshold_values:\n",
    "    predictions = (probabilities>threshold).astype(int)\n",
    "    predictions[predictions==0] = -1\n",
    "    print(\"Threshold {} : Precsion {} : Recall {}\".format(threshold.round(3), metrics.precision_score(baby_target,predictions).round(3), metrics.recall_score(baby_target,predictions).round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe794b82-b23c-4344-a32c-32ee564e08ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
