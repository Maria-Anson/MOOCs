> ## Linear Classifiers & Logistic Regression
> 
> Total points 5
> 
> ### 1.
> 
> Question 1
> 
> (True/False) A linear classifier assigns the predicted class based on the sign of Score(x)=wTh(x)\mbox{Score}(x) = \mathbf{w}^T h(\mathbf{x}).
> 
> 1 point
> 

      True 
> 
>  False 
> 
> ### 2.
> 
> Question 2
> 
> (True/False) For a conditional probability distribution over y∣xy | \mathbf{x}y∣x, where yyy takes on two values (+1, -1, i.e. good review, bad review) P(y=+1∣x)+P(y=−1∣x)=1P(y = +1 | \mathbf{x}) + P(y = -1 | \mathbf{x}) = 1P(y=+1∣x)+P(y=−1∣x)=1.
> 
> 1 point
> 

      True 
> 
>  False 
> 
> ### 3.
> 
> Question 3
> 
> Which function does logistic regression use to “squeeze” the real line to [0, 1]?
> 
> 1 point
> 

      Logistic function 
> 
>  Absolute value function 
> 
>  Zero function 
> 
> ### 4.
> 
> Question 4
> 
> If Score(x)=wTh(x)>0\mbox{Score}(x) = \mathbf{w}^T h(\mathbf{x}) > 0, which of the following is true about P(y=+1∣x)P(y = +1 | \mathbf{x})P(y=+1∣x)?
> 
> 1 point
> 
>  P(y = +1 | x) <= 0.5 
> 

      P(y = +1 | x) > 0.5 
> 
>  Can’t say anything about P(y = +1 | x) 
> 
> ### 5.
> 
> Question 5
> 
> Consider training a 1 vs. all multiclass classifier for the problem of digit recognition using logistic regression. There are 10 digits, thus there are 10 classes. How many logistic regression classifiers will we have to train?
> 
> 1 point
> 
> Enter answer here
>
      10
