# State-action value function
> ### 1.
> 
> Question 1
> 
> Which of the following accurately describes the state-action value function Q(s,a)?
> 
> 1 / 1 point
> 

      It is the return if you start from state s, take action a (once), then behave optimally after that. 
> 
>  It is the return if you start from state s and repeatedly take action a. 
> 
>  It is the return if you start from state s and behave optimally. 
> 
>  It is the immediate reward if you start from state and take action a (once). 
> 
> Correct
> 
> ### 2.
> 
> Question 2
> 
> You are controlling a robot that has 3 actions: ← (left), → (right) and STOP. From a given state s, you have computed Q(s, ←) = -10, Q(s, →) = -20, Q(s, STOP) = 0.
> 
> What is the optimal action to take in state s?
> 
> 1 / 1 point
> 

      STOP 
> 
>  ← (left) 
> 
>  → (right) 
> 
>  Impossible to tell 
> 
> Correct
> 
> ### 3.
> 
> Question 3
> 
> For this problem, \gamma = 0.25\. The diagram below shows the return and the optimal action from each state. Please compute Q(5, ←).
> 
> ![](https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/7fd3eb06-0d98-4ace-869a-0b26713e5dd4image2.png?expiry=1659225600000&hmac=Jxcr47wwhT_lTE4C9vF3QP_Ly4fZNXqOQqtQblqhkhg)
> 
> 1 / 1 point
> 

      0.625 
> 
>  0.391 
> 
>  1.25 
> 
>  2.5 
> 
> Correct
>
> -- https://www.coursera.org/learn/unsupervised-learning-recommenders-reinforcement-learning/exam/yGtub/state-action-value-function/view-attempt#uM8BXH-legend
